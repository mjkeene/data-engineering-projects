{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69a8c90e-de2d-40ec-82be-219f1a2523c4",
   "metadata": {},
   "source": [
    "<h2>Pandas vs Polars Speed</h2>\n",
    "\n",
    "https://pypi.org/project/polars-lts-cpu/\n",
    "\n",
    "* `Polars` is a DataFrame interface on top of an OLAP Query Engine implemented in Rust using Apache Arrow Columnar Format as the memory model.\n",
    "\n",
    "* Run an inline SQL query\n",
    "```bash\n",
    "> polars -c \"SELECT species, AVG(sepal_length) AS avg_sepal_length, AVG(sepal_width) AS avg_sepal_width FROM read_csv('docs/assets/data/iris.csv') GROUP BY species;\"\n",
    "```\n",
    "\n",
    "* `Polars` can handle larger-than-RAM data\n",
    "* If you have data that does not fit into memory, Polars' query engine is able to process your query (or parts of your query) in a streaming fashion. This drastically reduces memory requirements, so you might be able to process your 250GB dataset on your laptop. Collect with collect(streaming=True) to run the query streaming. (This might be a little slower, but it is still very fast!)\n",
    "\n",
    "* Benchmark testing vs. pandas, duckDB, PySpark, Dask:\n",
    "  * https://pola.rs/posts/benchmarks/\n",
    "---\n",
    "<h3>Why is Polars better than Pandas?</h3>\n",
    "\n",
    "Polars is able to work with datasets larger than RAM through a combination of design choices and optimizations that differ significantly from how pandas operates. Here are some key factors:\n",
    "\n",
    "1. Lazy Evaluation & Query Optimization:\n",
    "Polars supports lazy evaluation, meaning that it builds an execution plan rather than executing operations immediately. This allows it to optimize the computation (e.g., by fusing operations) and process data in chunks, which is much more memory-efficient.\n",
    "\n",
    "2. Columnar Memory Layout:\n",
    "Polars uses a columnar data format similar to Apache Arrow. This layout allows for better CPU cache utilization and efficient vectorized operations, minimizing memory overhead.\n",
    "\n",
    "3. Memory Mapping and Out-of-Core Processing:\n",
    "Polars can use memory mapping to work with data on disk as if it were in memory, which is beneficial for handling large datasets. This approach allows you to work with files larger than the available RAM by loading only necessary parts into memory as needed.\n",
    "\n",
    "4. Parallel Processing:\n",
    "Being built in Rust, Polars leverages modern hardware capabilities more effectively, allowing for parallel processing of data. This means that multiple CPU cores can work on different parts of the data concurrently, improving both speed and memory utilization.\n",
    "\n",
    "5. Efficient Data Structures:\n",
    "While pandas uses Python objects under the hood (with many operations relying on interpreted Python code), Polars is written in Rust and is designed to avoid unnecessary memory copies, reducing the overall memory footprint.\n",
    "\n",
    "In contrast, pandas is primarily designed for in-memory analysis. It loads entire datasets into RAM, which makes it straightforward for small to moderately sized datasets but problematic when the dataset size exceeds the available memory.\n",
    "\n",
    "Overall, Polars' design is oriented towards modern data processing requirements, including handling larger-than-RAM datasets efficiently through lazy evaluation, memory mapping, and highly optimized, parallelized computations.\n",
    "\n",
    "---\n",
    "<h3>Why is Pandas better than Polars?</h3>\n",
    "\n",
    "* Pandas still has some advantages over polars.\n",
    "\n",
    "1. Mature Ecosystem & Extensive Community Support\n",
    "* Pandas has been around for over a decade and is widely used in data science, finance, and academia.\n",
    "* There are more tutorials, Stack Overflow answers, and third-party integrations compared to Polars.\n",
    "* Many data science libraries (e.g., scikit-learn, seaborn, statsmodels) work seamlessly with pandas.\n",
    "\n",
    "2. More Built-in Functionality\n",
    "\n",
    "* Pandas has more statistical functions and built-in support for functions like:\n",
    "`df.corr(), df.cov(), df.rank(), df.interpolate(), df.rolling()`\n",
    "\n",
    "* Polars has fewer built-in statistical methods (though you can use NumPy/SciPy with it).\n",
    "\n",
    "3. More Flexible Data Structures\n",
    "\n",
    "* Pandas supports heterogeneous data types within a single column (e.g., a mix of strings, numbers, and NaNs).\n",
    "* Polars enforces a strict columnar format, so every column must have a single data type.\n",
    "* Pandas also supports multi-indexing, which can be useful for hierarchical data.\n",
    "\n",
    "4. Easier for Small Datasets & Quick Exploratory Analysis\n",
    "\n",
    "* If youâ€™re working with a small dataset (< 1M rows), pandas is often \"fast enough\" and has a more intuitive API.\n",
    "* The interactive experience with Jupyter notebooks is more natural in pandas.\n",
    "\n",
    "5. Better Support for Row-wise Operations\n",
    "\n",
    "* Since pandas is row-based (whereas Polars is columnar), row-wise operations (e.g., `apply()`) are more straightforward in pandas.\n",
    "* Polars discourages row-wise operations and instead pushes for vectorized, columnar computations.\n",
    "\n",
    "** <b>TL;DR: Pandas is still better for small-scale data science, flexible data structures, and statistics-heavy tasks. But for performance, scalability, and large datasets, Polars is the clear winner</b>\n",
    "\n",
    "---\n",
    "* Note that `polars` does not support Mac OS M1 chip, directly installing the `polars` library leads to issues when importing.\n",
    "* https://github.com/pola-rs/polars/issues/11650\n",
    "* Use the `polars-lts-cpu` \n",
    "\n",
    "\n",
    "\n",
    "```python\n",
    "import sys\n",
    "\n",
    "!{sys.executable} -m pip install polars-lts-cpu\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "912bf2a8-61af-4dc6-b80f-ccea333cd43e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pandas sum: 49499968634 (Time: 9.29749 sec)\n",
      "Polars sum: 49499968634 (Time: 3.34252 sec)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import polars as pl\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "# Generate a large dataset (1 billion rows)\n",
    "N = 1_000_000_000\n",
    "data = {\"col1\": np.random.randint(0, 100, size=N)}\n",
    "\n",
    "# Benchmark Pandas\n",
    "pandas_start = time.time()\n",
    "df_pandas = pd.DataFrame(data)\n",
    "sum_pandas = df_pandas[\"col1\"].sum()\n",
    "pandas_time = time.time() - pandas_start\n",
    "\n",
    "# Benchmark Polars\n",
    "polars_start = time.time()\n",
    "df_polars = pl.DataFrame(data)\n",
    "sum_polars = df_polars[\"col1\"].sum()\n",
    "polars_time = time.time() - polars_start\n",
    "\n",
    "# Print results\n",
    "print(f\"Pandas sum: {sum_pandas} (Time: {pandas_time:.5f} sec)\")\n",
    "print(f\"Polars sum: {sum_polars} (Time: {polars_time:.5f} sec)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e95a0a95-20f8-47f0-be70-987c9124ddd9",
   "metadata": {},
   "source": [
    "* With the 1B rows, polars' runtime is consistently ~3x faster than pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53a1a8e9-1a0e-43cd-8e9a-cfc8a9e097bd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb383dd-b717-445a-a139-d7d84a69a324",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
