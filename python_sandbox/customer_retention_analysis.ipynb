{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4c92ba6e-d5f5-4a4d-b76a-2ecebc4ff4a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80ac923-7e74-4c85-983b-83f978029e5b",
   "metadata": {},
   "source": [
    "Explanation of the dataset:\n",
    "\n",
    "* num_summaries: The number of summaries created by the user.\n",
    "* slack_integration: Whether the user integrated Slack (1 = Yes, 0 = No).\n",
    "* days_to_first_summary: Days taken by the user to create their first summary.\n",
    "* email_clicks: Number of email clicks the user interacted with.\n",
    "* retained_week4: Whether the user was retained by week 4 (1 = Retained, 0 = Churned)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1baa9ee9-7d87-4a2d-a24c-7fb351ee9ccf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simplified sample user engagement mock dataset for 20 users\n",
    "\n",
    "num_summaries = [15, 8, 12, 17, 2, 20, 2, 24, 26, 3, 1, 32, 34, 1, 38, 40, 42, 7, 46, 4]\n",
    "slack_integration = [0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1]\n",
    "days_to_first_summary = [2, 1, 1, 1, 9, 2, 8, 1, 2, 8, 6, 1, 2, 5, 1, 1, 2, 18, 1, 8]\n",
    "email_clicks = [3, 5, 7, 3, 0, 13, 1, 16, 3, 1, 0, 12, 3, 2, 5, 3, 32, 1, 9, 2]\n",
    "retained_week4 = [1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0]\n",
    "\n",
    "data = {\n",
    "    'num_summaries': num_summaries,\n",
    "    'slack_integration': slack_integration,\n",
    "    'days_to_first_summary': days_to_first_summary,\n",
    "    'email_clicks': email_clicks,\n",
    "    'retained_week4': retained_week4\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d8d6720e-a7f1-48e5-acbf-7ce020723ae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_summaries</th>\n",
       "      <th>slack_integration</th>\n",
       "      <th>days_to_first_summary</th>\n",
       "      <th>email_clicks</th>\n",
       "      <th>retained_week4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   num_summaries  slack_integration  days_to_first_summary  email_clicks  \\\n",
       "0             15                  0                      2             3   \n",
       "1              8                  1                      1             5   \n",
       "2             12                  1                      1             7   \n",
       "3             17                  1                      1             3   \n",
       "4              2                  0                      9             0   \n",
       "\n",
       "   retained_week4  \n",
       "0               1  \n",
       "1               1  \n",
       "2               1  \n",
       "3               1  \n",
       "4               0  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9788115d-041f-4ab1-937a-1c1e472b2a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features to evaluate (X) and target variable of retained after week 4 (y)\n",
    "\n",
    "X = df[['num_summaries', 'slack_integration', 'days_to_first_summary', 'email_clicks']]\n",
    "y = df['retained_week4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7e195d93-7f9f-4d99-8391-6f555516ed81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split into train and test sets\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "828b35bf-8cbe-41c1-b13d-db038fa04fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train logistic regression model\n",
    "\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3fbc83ed-c293-4647-9439-604c21e79af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: num_summaries, Coefficient: 0.4940\n",
      "Feature: slack_integration, Coefficient: 0.0304\n",
      "Feature: days_to_first_summary, Coefficient: -0.3009\n",
      "Feature: email_clicks, Coefficient: 0.2333\n"
     ]
    }
   ],
   "source": [
    "# Get feature importance (coefficients)\n",
    "\n",
    "coefficients = model.coef_[0]\n",
    "features = X.columns\n",
    "for feature, coef in zip(features, coefficients):\n",
    "    print(f\"Feature: {feature}, Coefficient: {coef:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "058262c6-e17e-41c5-9acc-78ce2198b263",
   "metadata": {},
   "source": [
    "<h3>Feature, Coefficient, and Interpretation of coefficient meaning</h3>\n",
    "\n",
    "| **Feature**               | **Coefficient** | **Interpretation**                                                                 |\n",
    "|---------------------------|-----------------|-----------------------------------------------------------------------------------|\n",
    "| `num_summaries`            | **+0.4940**       | More summaries strongly correlate with higher retention.                                  \n",
    "| `slack_integration`        | **+0.0304**        | Users integrating Slack have a very slightly higher association of retention.      |\n",
    "| `days_to_first_summary`    | **-0.3009**        | Users taking longer to create their first summary are less correlated with retention.|\n",
    "| `email_clicks`             | **+0.2333**       | Users clicking more emails have a small-medium but positive correlation with retention. |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dc1df44-5923-4b44-9c3b-b5338fce5d23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, 1, 1, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Predict retention probabilities\n",
    "\n",
    "y_pred_prob = model.predict_proba(X_test)[:, 1]  # Probability of retention\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0afe7d8b-f6e0-4c15-943f-c5c6228717f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n"
     ]
    }
   ],
   "source": [
    "# Evaluate model performance - we're 100% accurate!\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2925d35-b87f-40b2-b403-2b57e98117bb",
   "metadata": {},
   "source": [
    "<h2>Interpretation of Logistic Regression Coefficients:</h2>\n",
    "\n",
    "* Magnitude: The magnitude of the coefficient indicates how strongly the feature is associated the outcome, but it's not constrained to a specific range like -1 to 1.\n",
    "* Sign: The sign of the coefficient (+ or −) tells you the direction of the relationship:\n",
    "  * Positive coefficient: The feature is correlated with an increase in the likelihood of the outcome (retention in this case).\n",
    "  * Negative coefficient: The feature is correlated with a decrease in the likelihood of the outcome.\n",
    "\n",
    "It is important to note that a logistic regression shows correlation, not causality.\n",
    "\n",
    "<b> Why?</b>\n",
    "\n",
    "1. Correlation vs. Causation – Logistic regression can identify associations between independent variables (features) and the dependent variable (outcome), but it does not prove that changes in one variable cause changes in the outcome.\n",
    "\n",
    "2. Omitted Variable Bias – If important confounding variables are missing from the model, the relationships detected may be spurious or misleading.\n",
    "\n",
    "3. Reverse Causality – Logistic regression does not establish the direction of influence. For example, if you find a significant relationship between stress and heart disease, it's unclear whether stress causes heart disease or if heart disease leads to stress.\n",
    "\n",
    "4. Experimental vs. Observational Data – Logistic regression is often used with observational data, where confounding factors and biases make it difficult to determine causality. Causal inference usually requires experimental designs (like randomized controlled trials) or advanced statistical techniques such as instrumental variables or causal inference frameworks (e.g., Directed Acyclic Graphs, propensity score matching).\n",
    "\n",
    "\n",
    "<b>Example</b>\n",
    "\n",
    "Feature: num_summaries, Coefficient: 0.4940\n",
    "\n",
    "This means that for every one-unit increase in num_summaries, the log-odds of the user being retained (increased probability of retention) increases by 0.4940, holding all other variables constant.\n",
    "\n",
    "<h3>Converting Coefficients to Odds Ratio:</h3>\n",
    "\n",
    "To better interpret the impact, you can convert the log-odds to an odds ratio by exponentiating the coefficient:\n",
    "\n",
    "$Odds Ratio=e^{coefficient}$\n",
    "\n",
    "For the coefficient of 0.4940, the odds ratio would be:\n",
    "\n",
    "$e^{0.4940} ≈ 1.639$\n",
    "\n",
    "<h3>Interpretation of Odds Ratio:</h3>\n",
    "\n",
    "* An odds ratio of 1.639 means that for every 1 additional summary a user has, the odds of retention increase by a factor of 1.639.\n",
    "* If the odds ratio were less than 1 (e.g., 0.5), it would mean the feature decreases the likelihood of retention.\n",
    "* An odds ratio of 1 means there is no effect on retention.\n",
    "\n",
    "\n",
    "<b>Takeaway</b>: Once we have discovered which features have the most impact on our target (retention at week 4 in this case - note that there are many other ways to define customer retention, and it largely depends on long-term goals), we can take actions to influence customer behavior (e.g., ensure that onboarding is as frictionless as possible to get those first few summaries generated). If a customer has not met those key metrics by a certain point, trigger some action like an outreach email, trial extension, etc. These can be validated with A/B testing over time to see which actions are most effective at influencing churn."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a003564-9628-438e-9d79-7662eff5115f",
   "metadata": {},
   "source": [
    "---\n",
    "<h2>Quick Recap of A/B Testing</h2>\n",
    "\n",
    "<h4>1. Define the experiment goals</h4>\n",
    "\n",
    "Example goal: \"Test if personalized onboarding emails or extended trials improve retention.\"\n",
    "\n",
    "Hypothesis: Either intervention increases retention after 30 days.\n",
    "\n",
    "<b>Note that this is actually an A/B/C test</b>\n",
    "\n",
    "* Null Hypothesis ($H_{0}$): No difference in retention between groups.\n",
    "* Alternative Hypothesis ($H_{1}$): At least one treatment group improves retention over the control.\n",
    "\n",
    "<h4>2. Clarify what you define as success</h4>\n",
    "\n",
    "* Statistical significance (e.g., p-value < 0.05)\n",
    "   * This will tell us if the results are real (i.e., statistically significant) or due to random chance.\n",
    "   * If p < 0.05, we reject the null hypothesis, meaning at least one intervention significantly affects retention.\n",
    "   * p-value is good for a simple yes/no answer for \"is there a difference between the groups?\"; it is good for making one-time, discrete decisions like launch the new onboarding process or not.\n",
    "\n",
    "\n",
    "\n",
    "* Confidence Intervals (CIs)\n",
    "   * A 95% CI gives a range in which the true effect likely lies\n",
    "   * If Group B had a retention rate of 40%, then a 95% CI tells us that we are 95% confident that the true retention rate is between 35% and 45%.\n",
    "   * If two groups have overlapping confidence intervals, there may not be a significant difference.\n",
    "   * Use CI if you care about the magnitude of the effect, and not just statistical significance.\n",
    "   * Better for long-term business decisions and want a range estimate instead of a strict cutoff.\n",
    "\n",
    "* <b>It is best practice to use both p-values and confidence intervals, since p-values tell us if there is a difference that exists, and confidence intervals tell us how large the difference is.</b>\n",
    "\n",
    "* Will the retention be measured at a fixed time point (30 days) or as a survival curve (Kaplan-Meier analysis)?\n",
    "   * This can be used to track how long users stay engaged over time (not just a strict cutoff like 30 days).\n",
    "   * Kaplan-Meier curves can show differences in retention trends.\n",
    "   * <b>For example, maybe Group C shows higher retention early on, but drops off later.</b>\n",
    "\n",
    "<h4>3. Choose the key metrics:</h4>\n",
    "\n",
    "*  Retention Rate (e.g., % of users still active after 30 days)\n",
    "*  Churn Rate (e.g., % of users who stopped using the product)\n",
    "*  Engagement Metrics (e.g., number of summaries generated, Slack integration usage)\n",
    "\n",
    "<h4>4. Select the  target audience, ensuring randomization</h4>\n",
    "\n",
    "* New Users Only: Focus on users who sign up within a certain period (e.g., this month).\n",
    "* Randomized Assignment: Use a random split to ensure fair comparisons and avoid bias.\n",
    "* Example random split:\n",
    "  * <b>Group A (Control Group)</b>: Standard onboarding\n",
    "  * <b>Group B (Personal Email Group)</b>: Personalized onboarding email\n",
    "  * <b>Group C (Trial Extension Group)</b>: Extended trial if inactive by day 5\n",
    "\n",
    "<h4>5. Analyze Results</h4>\n",
    "\n",
    "* Use statistical tests (chi-square, t-test, ANOVA) to compare retention.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a66934-7e8b-4e09-a096-19f0a3ca42fd",
   "metadata": {},
   "source": [
    "---\n",
    "<h2>Better Alternatives for Retention Analysis</h2>\n",
    "\n",
    "* Logistic regression is a good starting point for ease of interpretation, but it has limitations.\n",
    "\n",
    "<b>Why Logistic Regression Works for Retention Analysis</b>\n",
    "\n",
    "1. Binary Outcome: Customer retention is often framed as a binary classification problem (e.g., \"retained\" = 1, \"churned\" = 0), making logistic regression a natural choice.\n",
    "2. Interpretability: Unlike complex machine learning models, logistic regression provides coefficients that indicate the impact of each factor on retention, making it easier to explain insights to stakeholders.\n",
    "3. Baseline Model: It serves as a good starting point before testing more advanced models like decision trees, random forests, or neural networks.\n",
    "\n",
    "\n",
    "<b>Potential Limitations</b>\n",
    "\n",
    "1. Assumes Linearity in Log-Odds: Logistic regression assumes a linear relationship between independent variables and log-odds of retention, which may not always be realistic.\n",
    "2. Ignores Interactions & Nonlinearity: Important interactions between factors (e.g., usage frequency × customer support engagement) may be missed unless explicitly modeled.\n",
    "3. Feature Engineering is Key: Retention is driven by complex behaviors, and raw variables alone may not be enough. You may need to create meaningful features (e.g., last login time, feature usage trends).\n",
    "\n",
    "\n",
    "<b>For deeper insights, consider using:</b>\n",
    "\n",
    "1. Random Forests/XGBoost – Capture nonlinear relationships and interactions.\n",
    "2. Survival Analysis – Predicts \"time until churn\" rather than just whether a customer churns.\n",
    "3. Causal Inference Methods – If you need to identify causal drivers rather than just correlations, methods like propensity score matching or instrumental variables might be useful.\n",
    "\n",
    "<b>A good first-pass approach:</b>\n",
    "\n",
    "1. Start with logistic regression for interpretability.\n",
    "2. Explore more advanced models (e.g., XGBoost, survival analysis) for improved accuracy.\n",
    "3. Test causal inference techniques if the goal is to find actionable retention levers (e.g., does sending an email boost retention?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cb10a47-8c14-4cf5-938a-71efeeb47065",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
