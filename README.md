<h2>Data Engineering Projects</h2>

Welcome to my data engineering repository! This repository showcases my projects, which demonstrate my skills in
building data pipelines, working with databases, processing large datasets, and applying engineering best practices.

<h3>Projects</h3>

| **Project Name**                                             | **Description**                                                                          | **Technologies Used**          |
|--------------------------------------------------------------|------------------------------------------------------------------------------------------|--------------------------------|
| [CSV to SQLite Data Pipeline](./csv_to_sqlite_data_pipeline) | A lightweight pipeline to extract, clean, and load CSV data into an SQLite database.   | Python, Pandas, SQLite         |
| *Upcoming Project*                                           | Placeholder for my next project! Stay tuned.                                            | TBD                            |
| *Upcoming Project*                                           | Placeholder for my next project! Stay tuned.                                            | TBD                            |


<h3>Skills Highlighted</h3>

* Data Pipelines: End-to-end pipelines to extract, transform, and load data.
* Database Management: Working with SQL databases like SQLite and PostgreSQL.
* Data Cleaning: Handling messy, real-world data using Python libraries.
* Data Integration: Combining multiple data sources into cohesive datasets.

<h3>How to Use</h3>

1. Clone the repository:
```
git clone https://github.com/<your-username>/data-engineering-projects.git
```

2. Navigate into a project folder:
```
cd csv_to_sqlite_data_pipeline
```

3. Follow the instructions in the project’s README to run the code.

<h3>Future Plans</h3>

This repository will be regularly updated with new data engineering projects to demonstrate:

* Advanced pipeline orchestration (e.g., Airflow, Prefect).
* Cloud-based data workflows (e.g., AWS, GCP, Snowflake).
* Distributed computing with Spark.
* Streaming data pipelines (e.g., Kafka, Kinesis).

<h3>About Me</h3>

I’m a passionate data engineer with experience in Python, SQL, and AWS, looking to solve real-world data problems.
Connect with me on [LinkedIn](https://www.linkedin.com/in/michael-james-keene/) or check out more of my work on
[GitHub](https://github.com/mjkeene).
